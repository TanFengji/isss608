[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-AY2023-24T4",
    "section": "",
    "text": "This is Fengji’s Quarto website for ISSS608"
  },
  {
    "objectID": "in-class/In-class_Ex03.html",
    "href": "in-class/In-class_Ex03.html",
    "title": "ISSS609-AY2023-24T4",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggstatsplot)\nexam &lt;- read_csv(\"../data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nset.seed(1234)\ngghistostats(data=exam, \n             x=ENGLISH, \n             type=\"parametric\", \n             test.value=60, \n             bin.args=list(color = \"black\", \n                           fill = \"grey50\", \n                           alpha=0.7), \n             normal.curve = FALSE, \n             normal.curve.args = list(linewidth=2), \n             xlab=\"English scores\")\n\n\n\n\n\nset.seed(1234)\ngghistostats(data=exam, \n             x=ENGLISH, \n             type=\"np\", \n             test.value=60, \n             bin.args=list(color = \"black\", \n                           fill = \"grey50\", \n                           alpha=0.7), \n             normal.curve = FALSE, \n             normal.curve.args = list(linewidth=2), \n             xlab=\"English scores\")\n\n\n\n\n\nexam_long = exam %&gt;%\n  pivot_longer(\n    cols = ENGLISH:SCIENCE,\n    names_to = \"SUBJECT\",\n    values_to = \"SCORES\") %&gt;%\n  filter(CLASS == \"3A\")\n\nhead(exam_long)\n\n# A tibble: 6 × 6\n  ID         CLASS GENDER RACE    SUBJECT SCORES\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n1 Student026 3A    Male   Chinese ENGLISH     68\n2 Student026 3A    Male   Chinese MATHS       87\n3 Student026 3A    Male   Chinese SCIENCE     66\n4 Student021 3A    Male   Chinese ENGLISH     70\n5 Student021 3A    Male   Chinese MATHS       90\n6 Student021 3A    Male   Chinese SCIENCE     72\n\n\n\nggwithinstats(\n  data= filter(exam_long, \n               SUBJECT %in% \n                 c(\"MATHS\", \"SCIENCE\")),\n  x = SUBJECT,\n  y = SCORES,\n  type = \"p\"\n)\n\nWarning in min(x): no non-missing arguments to min; returning Inf\n\n\nWarning in max(x): no non-missing arguments to max; returning -Inf\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE,\n  label.var = ID,\n  label.expression = ENGLISH &gt; 90 & MATHS &gt; 90\n)\n\nRegistered S3 method overwritten by 'ggside':\n  method from   \n  +.gg   ggplot2\n\n\n`stat_xsidebin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_ysidebin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "assignment_2.html",
    "href": "assignment_2.html",
    "title": "Take Home Assignment 2",
    "section": "",
    "text": "In this take-home exercise, we are required to:\n\nselect one data visualisation from the Take-home Exercise 1 submission prepared by your classmate,\ncritic the submission in terms of clarity and aesthetics,\nprepare a sketch for the alternative design by using the data visualisation design principles and best practices you had learned in Lesson 1 and 2.\nremake the original design by using ggplot2, ggplot2 extensions and tidyverse packages.\n\nFor this assignment, I selected Keke’s assignment 1 visualization 1 for evaluation. https://isss608keke.netlify.app/takehome/takehome1"
  },
  {
    "objectID": "assignment_2.html#introduction",
    "href": "assignment_2.html#introduction",
    "title": "Take Home Assignment 2",
    "section": "",
    "text": "In this take-home exercise, we are required to:\n\nselect one data visualisation from the Take-home Exercise 1 submission prepared by your classmate,\ncritic the submission in terms of clarity and aesthetics,\nprepare a sketch for the alternative design by using the data visualisation design principles and best practices you had learned in Lesson 1 and 2.\nremake the original design by using ggplot2, ggplot2 extensions and tidyverse packages.\n\nFor this assignment, I selected Keke’s assignment 1 visualization 1 for evaluation. https://isss608keke.netlify.app/takehome/takehome1"
  },
  {
    "objectID": "assignment_2.html#reproduce-visualization",
    "href": "assignment_2.html#reproduce-visualization",
    "title": "Take Home Assignment 2",
    "section": "Reproduce visualization",
    "text": "Reproduce visualization\nThe data preparation process is exactly the same as Keke’s original implementation.\n\npacman::p_load(ggplot2,lubridate,ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse)\n\noptions(readr.show_col_types = FALSE)\noptions(warn=-1)\n\nsetwd(\"./data/Take-home_Ex01/data\")\nfull_data &lt;-  list.files(\n                    pattern = \"*.csv\",\n                    full.names=T) %&gt;%\n                    lapply(read_csv) %&gt;%\n                    bind_rows()\n\n\ncleaned_data &lt;- full_data %&gt;%\n  mutate(across(c(`Nett Price($)`, `Area (SQM)`, `Unit Price ($ PSM)`), ~replace(., . == \"\" | . == \"-\", NA))) %&gt;%\n  mutate(\n    `Transacted Price ($)` = as.numeric(gsub(\",\", \"\", `Transacted Price ($)`)),\n    `Area (SQFT)` = as.numeric(`Area (SQFT)`),\n    `Unit Price ($ PSF)` = as.numeric(gsub(\",\", \"\", `Unit Price ($ PSF)`)),\n    `Sale Date` = dmy(`Sale Date`),\n    `Area (SQM)` = as.numeric(`Area (SQM)`),\n    `Unit Price ($ PSM)` = as.numeric(gsub(\",\", \"\", `Unit Price ($ PSM)`)),\n    `Nett Price($)` = ifelse(is.na(`Nett Price($)`),\n                             `Area (SQM)` * `Unit Price ($ PSM)`,\n                             as.numeric(gsub(\",\", \"\", `Nett Price($)`)))\n  )\n\nReproduce visualization for central region:\n\np1 &lt;- cleaned_data %&gt;%\n  filter(`Planning Region` == \"Central Region\") %&gt;% \n  group_by(Month = floor_date(`Sale Date`, \"month\"), `Type of Sale`, `Property Type`) %&gt;%\n  summarize(Average_Price = mean(`Unit Price ($ PSM)`, na.rm = TRUE), .groups = 'drop') %&gt;%\n  ggplot(aes(x = Month, y = Average_Price, color = `Type of Sale`)) +\n  geom_line() +\n  scale_x_date(date_breaks = \"3 month\", date_labels = \"%b %Y\") +\n  labs(\n    title = \"Central Region: Trend of Average Unit Prices Over Time\",\n    x = \"Month\",\n    y = \"Average Unit Price ($ PSM)\"\n  ) +\n  facet_wrap(~ `Property Type`, scales = \"free_y\", strip.position = \"bottom\") +  \n  theme(\n    plot.title = element_text(size = rel(1.5)),\n    legend.position = \"top\",\n    legend.text = element_text(size = rel(0.8)),\n    panel.grid.major = element_line(color = \"grey80\"),\n    panel.grid.minor = element_blank(),\n    plot.margin = margin(10, 10, 10, 10),\n    strip.text = element_text(size = rel(0.8)),  # adjust strip text size\n    axis.text.x = element_text(size = rel(0.8), angle = 45, hjust = 1, vjust = 1),  # adjust x-axis text size\n    axis.ticks.length = unit(-3, \"pt\"),  #aAdjust tick length\n    panel.spacing = unit(1, \"lines\")  # adjust spacing between facets\n  )\n\np1"
  },
  {
    "objectID": "assignment_2.html#critics",
    "href": "assignment_2.html#critics",
    "title": "Take Home Assignment 2",
    "section": "Critics",
    "text": "Critics\nOriginal write-up from Keke:\nIn the Central Region, Q1 2024 presents a stable pricing pattern for apartments, condominiums, and terrace houses, mirroring trends from the previous year. Conversely, detached houses experienced a significant rise in prices, followed by a pronounced dip, particularly within the sub-sale segment, which has now narrowed down to only resale transactions. It shows there was flutuation under Executive condominiums from March to December 2023, culminating in a complete absence of new sales in the subsequent quarter. Meanwhile, semi-detached houses witnessed a singular decline in June 2023, after which prices entered a gradual and steady climb, indicating a stabilizing market as progress through 2024.\nCritics:\n\nRegarding the statement “detached houses experienced a significant rise in prices, followed by a pronounced dip, particularly within the sub-sale segment”, this can be clearly observed from the graph. However, it is worth noticing that the sale number of detached houses is quite low in the sub-sale market (21 for the whole year as shown below). The sales volume is insufficient to accurately depict the sales trend.\n\n\nsub_sale_detach &lt;- cleaned_data %&gt;%\n  filter(`Planning Region` == \"Central Region\" & `Property Type` == \"Detached Houses\" & `Type of Sale` == \"Sub Sale\")\nlength(sub_sale_detach)\n\n[1] 21\n\n\nA better approach might be remove the monthly plot based on some conditions, e.g. remove if sale of current month is less than 10.\n\np2 &lt;- cleaned_data %&gt;%\n  filter(`Planning Region` == \"Central Region\") %&gt;% \n  group_by(Month = floor_date(`Sale Date`, \"month\"), `Type of Sale`, `Property Type`) %&gt;%\n  filter(n() &gt;= 10) %&gt;% \n  summarize(Average_Price = mean(`Unit Price ($ PSM)`, na.rm = TRUE), .groups = 'drop') %&gt;%\n  ggplot(aes(x = Month, y = Average_Price, color = `Type of Sale`)) +\n  geom_line() +\n  ylim(10000,45000) + \n  scale_x_date(date_breaks = \"3 month\", date_labels = \"%b %Y\") +\n  labs(\n    title = \"Central Region: Trend of Average Unit Prices Over Time\",\n    x = \"Month\",\n    y = \"Average Unit Price ($ PSM)\"\n  ) +\n  facet_wrap(~ `Property Type`, scales = \"free_y\", strip.position = \"bottom\") +  \n  theme(\n    plot.title = element_text(size = rel(1.5)),\n    legend.position = \"top\",\n    legend.text = element_text(size = rel(0.8)),\n    panel.grid.major = element_line(color = \"grey80\"),\n    panel.grid.minor = element_blank(),\n    plot.margin = margin(10, 10, 10, 10),\n    strip.text = element_text(size = rel(0.8)),  # adjust strip text size\n    axis.text.x = element_text(size = rel(0.8), angle = 45, hjust = 1, vjust = 1),  # adjust x-axis text size\n    axis.ticks.length = unit(-3, \"pt\"),  #aAdjust tick length\n    panel.spacing = unit(1, \"lines\")  # adjust spacing between facets\n  )\n\np2\n\n\n\n\n\nRegarding the highlight of the fluctuation under executive condominiums compared to other property types, it is rather misleading. The graphs for different properties do not share the same y-axis scales. Highlighting fluctuations with a smaller scale can mislead users. A better visualization should have consistent scales across different property types.\n\n\np2 &lt;- cleaned_data %&gt;%\n  filter(`Planning Region` == \"Central Region\") %&gt;% \n  group_by(Month = floor_date(`Sale Date`, \"month\"), `Type of Sale`, `Property Type`) %&gt;%\n  summarize(Average_Price = mean(`Unit Price ($ PSM)`, na.rm = TRUE), .groups = 'drop') %&gt;%\n  ggplot(aes(x = Month, y = Average_Price, color = `Type of Sale`)) +\n  geom_line() +\n  ylim(10000,45000) + \n  scale_x_date(date_breaks = \"3 month\", date_labels = \"%b %Y\") +\n  labs(\n    title = \"Central Region: Trend of Average Unit Prices Over Time\",\n    x = \"Month\",\n    y = \"Average Unit Price ($ PSM)\"\n  ) +\n  facet_wrap(~ `Property Type`, scales = \"free_y\", strip.position = \"bottom\") +  \n  theme(\n    plot.title = element_text(size = rel(1.5)),\n    legend.position = \"top\",\n    legend.text = element_text(size = rel(0.8)),\n    panel.grid.major = element_line(color = \"grey80\"),\n    panel.grid.minor = element_blank(),\n    plot.margin = margin(10, 10, 10, 10),\n    strip.text = element_text(size = rel(0.8)),  # adjust strip text size\n    axis.text.x = element_text(size = rel(0.8), angle = 45, hjust = 1, vjust = 1),  # adjust x-axis text size\n    axis.ticks.length = unit(-3, \"pt\"),  #aAdjust tick length\n    panel.spacing = unit(1, \"lines\")  # adjust spacing between facets\n  )\n\np2"
  },
  {
    "objectID": "assignment_2.html#conclusion",
    "href": "assignment_2.html#conclusion",
    "title": "Take Home Assignment 2",
    "section": "Conclusion",
    "text": "Conclusion\nBy combining critic 1 and 2, a more impartial visualization could be created.\n\np2 &lt;- cleaned_data %&gt;%\n  filter(`Planning Region` == \"Central Region\") %&gt;% \n  group_by(Month = floor_date(`Sale Date`, \"month\"), `Type of Sale`, `Property Type`) %&gt;%\n  filter(n() &gt;= 10) %&gt;% \n  summarize(Average_Price = mean(`Unit Price ($ PSM)`, na.rm = TRUE), .groups = 'drop') %&gt;%\n  ggplot(aes(x = Month, y = Average_Price, color = `Type of Sale`)) +\n  geom_line() +\n  ylim(10000,45000) + \n  scale_x_date(date_breaks = \"3 month\", date_labels = \"%b %Y\") +\n  labs(\n    title = \"Central Region: Trend of Average Unit Prices Over Time\",\n    x = \"Month\",\n    y = \"Average Unit Price ($ PSM)\"\n  ) +\n  facet_wrap(~ `Property Type`, scales = \"free_y\", strip.position = \"bottom\") +  \n  theme(\n    plot.title = element_text(size = rel(1.5)),\n    legend.position = \"top\",\n    legend.text = element_text(size = rel(0.8)),\n    panel.grid.major = element_line(color = \"grey80\"),\n    panel.grid.minor = element_blank(),\n    plot.margin = margin(10, 10, 10, 10),\n    strip.text = element_text(size = rel(0.8)),  # adjust strip text size\n    axis.text.x = element_text(size = rel(0.8), angle = 45, hjust = 1, vjust = 1),  # adjust x-axis text size\n    axis.ticks.length = unit(-3, \"pt\"),  #aAdjust tick length\n    panel.spacing = unit(1, \"lines\")  # adjust spacing between facets\n  )\n\np2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "assignment_1.html",
    "href": "assignment_1.html",
    "title": "Take Home Assignment 1",
    "section": "",
    "text": "Our dataset contains transaction records for both public and private residential properties from January 1, 2023, to March 31, 2024. The task is to provide insights into the private residential market and its sub-markets in Singapore for the first quarter of 2024, with the help of visualization to describe and discuss the trends."
  },
  {
    "objectID": "assignment_1.html#introduction-and-task",
    "href": "assignment_1.html#introduction-and-task",
    "title": "Take Home Assignment 1",
    "section": "",
    "text": "Our dataset contains transaction records for both public and private residential properties from January 1, 2023, to March 31, 2024. The task is to provide insights into the private residential market and its sub-markets in Singapore for the first quarter of 2024, with the help of visualization to describe and discuss the trends."
  },
  {
    "objectID": "assignment_1.html#pre-processing",
    "href": "assignment_1.html#pre-processing",
    "title": "Take Home Assignment 1",
    "section": "Pre-processing",
    "text": "Pre-processing\nImporting libraries:\n\nlibrary(readr)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ purrr     1.0.2\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nMerge the datasets (5 csv) into 1 dataframe:\n\noptions(readr.show_col_types = FALSE)\noptions(warn=-1)\n\n#merge all the CSV files (5 in total) into one dataframe\ndf &lt;- list.files(path='./data/Take-home_Ex01/data', full.names = TRUE) %&gt;% \n  lapply(read_csv) %&gt;% \n  bind_rows \n\n\nunique(df$`Purchaser Address Indicator`)\n\n[1] \"HDB\"     \"Private\" \"N.A\"    \n\n\nAs shown above, there are 3 types in Purchaser Address Indicator. Since we only concern about private residential market, transcation records for ‘HDB’ and ‘N.A.’ will be removed.\n\ndf &lt;- df %&gt;%\n  filter(`Purchaser Address Indicator` == \"Private\")\n\nAlso, the ‘Sale Date’ is in string format, which will be converted to Date format for better visualization.\n\ndf$`Sale Date` = as.Date(df$`Sale Date`, format = \"%d %b %Y\")"
  },
  {
    "objectID": "assignment_1.html#visualization-1",
    "href": "assignment_1.html#visualization-1",
    "title": "Take Home Assignment 1",
    "section": "Visualization 1",
    "text": "Visualization 1\nTransaction trend across different property type\n\ndf_tran = df %&gt;%\n  group_by(month=format(`Sale Date`, format=\"%y'%m\"), `Property Type`) %&gt;%\n  summarize(transactions = sum(`Number of Units`))\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\ndf_tran_total = df %&gt;%\n  group_by(month=format(`Sale Date`, format=\"%y'%m\")) %&gt;%\n  summarize(transactions = sum(`Number of Units`))\ndf_tran_total$`Property Type` = \"Total\"\ndf_tran &lt;- rbind(df_tran, df_tran_total)\n\n\nggplot(df_tran, aes(x=`month`, y=`transactions`, group=`Property Type`, color=`Property Type`)) +\n  geom_line() +\n  ggtitle(\"Transaction trend across different property type\")+\n  xlab(\"Month\")+\n  ylab(\"No. of Transactions\")\n\n\n\n\nFrom the graph, the transaction numbers for detached house, executive condominium, semi-detached house and terrace house are rather consistent, and relatively small compared to the apartment and condo. Although the transaction number for both apartment and condo are high, the condo changes smoother across time compared to apartment. The fluctuations in the total transaction number are mainly due to apartment. Since July 2023, the general trend for the private residential market is shrinking. For the 2024 Q1, transaction numbers reaches the lowest point across the last year."
  },
  {
    "objectID": "assignment_1.html#visualization-2",
    "href": "assignment_1.html#visualization-2",
    "title": "Take Home Assignment 1",
    "section": "Visualization 2",
    "text": "Visualization 2\nUnit price trend across different property type\n\ndf_unit_price = df %&gt;%\n  group_by(month=format(`Sale Date`, format=\"%y'%m\"), `Property Type`) %&gt;%\n  summarize(`Unit Price ($ PSF)` = mean(`Unit Price ($ PSF)`))\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\n\n\nggplot(df_unit_price, aes(x=`month`, y=`Unit Price ($ PSF)`, group=`Property Type`, color=`Property Type`)) +\n  geom_line() +\n  ggtitle(\"Unit Price (PSF) across different property type\")+\n  xlab(\"Month\")+\n  ylab(\"Mean Unit Price ($ PSF)\")\n\n\n\n\nFor condo, detached house, semi-detached house and terrace house, the unit price fluctuates a lot during the year, but at the year end, the unit prices eventually changes back around the beginning of the year. For apartment’s unit price, the general trend is decreasing with some fluctuations. For the executive condo, the unit price changes is usually very minor compared to the rest, but consistently increases. For the 2024 Q1, it’s unit price drop a little bit."
  },
  {
    "objectID": "assignment_1.html#visualization-3",
    "href": "assignment_1.html#visualization-3",
    "title": "Take Home Assignment 1",
    "section": "Visualization 3",
    "text": "Visualization 3\nTransactions across different areas (East, North east, central, north, west)\n\nunique(df$`Planning Region`)\n\n[1] \"East Region\"       \"North East Region\" \"Central Region\"   \n[4] \"North Region\"      \"West Region\"      \n\n\n\ndf_tran_area = df %&gt;%\n  group_by(month=format(`Sale Date`, format=\"%y'%m\"), `Planning Region`) %&gt;%\n  summarize(transactions = sum(`Number of Units`))\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\n\n\nggplot(df_tran_area, aes(x=`month`, y=`transactions`, group=`Planning Region`, color=`Planning Region`)) +\n  geom_line() +\n  ggtitle(\"Transactions across different regions\")+\n  xlab(\"Month\")+\n  ylab(\"No. of transactions\")\n\n\n\n\nThe transactions for east, north east, north and west regions are rather consistent across the year. The transactions for the central region increased significantly since the start of 2023, fluctuates from 2023 April to Augest, and then slowly decreased all the way until the Q1 of 2024. This helps explain the fluctuations in visualization 1, which is likely be caused by the fluctuations from the condo of central region."
  },
  {
    "objectID": "assignment_3.html",
    "href": "assignment_3.html",
    "title": "Take Home Assignment 3",
    "section": "",
    "text": "I picked MC3 of VAST Challenge 2024. The objective of the exercise is to help help FishEye to better identify bias, track behavior changes, and infer temporal patterns from the knowledge graphs prepared by their data analysts.\nWe will focus on task 1 in the mini-challenge, which is:\n\nFishEye analysts want to better visualize changes in corporate structures over time. Create a visual analytics approach that analysts can use to highlight temporal patterns and changes in corporate structures. Examine the most active people and businesses using visual analytics."
  },
  {
    "objectID": "assignment_3.html#introduction",
    "href": "assignment_3.html#introduction",
    "title": "Take Home Assignment 3",
    "section": "",
    "text": "I picked MC3 of VAST Challenge 2024. The objective of the exercise is to help help FishEye to better identify bias, track behavior changes, and infer temporal patterns from the knowledge graphs prepared by their data analysts.\nWe will focus on task 1 in the mini-challenge, which is:\n\nFishEye analysts want to better visualize changes in corporate structures over time. Create a visual analytics approach that analysts can use to highlight temporal patterns and changes in corporate structures. Examine the most active people and businesses using visual analytics."
  },
  {
    "objectID": "assignment_3.html#data-preparation",
    "href": "assignment_3.html#data-preparation",
    "title": "Take Home Assignment 3",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nLoad library and data\n\n\nShow code\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, graphlayouts, ggforce, skimr, tidytext, tidyverse, RColorBrewer) \noptions(warn=-1)\n\njson_text &lt;- readLines(\"data/mc3.json\")\njson_text_fixed &lt;- gsub(\"NaN\", \"null\", json_text)\nwriteLines(json_text_fixed, \"data/mc3_fixed.json\")\nmc3_data &lt;- fromJSON(\"data/mc3_fixed.json\")\n\n\n\n\nNodes and Edges overview\n\nNodesEdges\n\n\n\n\nShow code\nmc3_nodes &lt;- as_tibble(mc3_data$nodes)\nglimpse(mc3_nodes)\n\n\nRows: 60,520\nColumns: 15\n$ type                &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organizatio…\n$ country             &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", …\n$ ProductServices     &lt;chr&gt; \"Unknown\", \"Furniture and home accessories\", \"Food…\n$ PointOfContact      &lt;chr&gt; \"Rebecca Lewis\", \"Michael Lopez\", \"Steven Robertso…\n$ HeadOfOrg           &lt;chr&gt; \"Émilie-Susan Benoit\", \"Honoré Lemoine\", \"Jules La…\n$ founding_date       &lt;chr&gt; \"1954-04-24T00:00:00\", \"2009-06-12T00:00:00\", \"202…\n$ revenue             &lt;dbl&gt; 5994.73, 71766.67, 0.00, 0.00, 4746.67, 46566.67, …\n$ TradeDescription    &lt;chr&gt; \"Unknown\", \"Abbott-Gomez is a leading manufacturer…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Pelagia Alethea Mordoc…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Existing Cor…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Automatic Import\", \"Automatic…\n$ id                  &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Ab…\n$ dob                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nOnly type, and id are selected.\n\n\nShow code\nmc3_nodes &lt;- as_tibble(mc3_data$nodes) %&gt;%\n  mutate(id=as.character(id), \n         type=as.character(type)) %&gt;%\n  select(id, type)\n\n\nBelow is the distribution of type column in nodes. It indicates that most entities are person, with some companies and CEOs. Other entities are negligible.\n\nmc3_nodes$type %&gt;% unique()\n\n[1] \"Entity.Organization.Company\"         \n[2] \"Entity.Organization.LogisticsCompany\"\n[3] \"Entity.Organization.FishingCompany\"  \n[4] \"Entity.Organization.FinancialCompany\"\n[5] \"Entity.Organization.NewsCompany\"     \n[6] \"Entity.Organization.NGO\"             \n[7] \"Entity.Person\"                       \n[8] \"Entity.Person.CEO\"                   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nmc3_edges &lt;- as_tibble(mc3_data$links)\nhead(mc3_edges)\n\n\n# A tibble: 6 × 11\n  start_date          type   `_last_edited_by` `_last_edited_date` `_date_added`\n  &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;             &lt;chr&gt;               &lt;chr&gt;        \n1 2016-10-29T00:00:00 Event… Pelagia Alethea … 2035-01-01T00:00:00 2035-01-01T0…\n2 2035-06-03T00:00:00 Event… Niklaus Oberon    2035-07-15T00:00:00 2035-07-15T0…\n3 2028-11-20T00:00:00 Event… Pelagia Alethea … 2035-01-01T00:00:00 2035-01-01T0…\n4 2024-09-04T00:00:00 Event… Pelagia Alethea … 2035-01-01T00:00:00 2035-01-01T0…\n5 2034-11-12T00:00:00 Event… Pelagia Alethea … 2035-01-01T00:00:00 2035-01-01T0…\n6 2007-04-06T00:00:00 Event… Pelagia Alethea … 2035-01-01T00:00:00 2035-01-01T0…\n# ℹ 6 more variables: `_raw_source` &lt;chr&gt;, `_algorithm` &lt;chr&gt;, source &lt;chr&gt;,\n#   target &lt;chr&gt;, key &lt;int&gt;, end_date &lt;chr&gt;\n\n\n\n\n\n\n\n\n\n\nShow code\nmc3_edges &lt;- as_tibble(mc3_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source = as.character(source), target=as.character(target), \n         type = as.character(type),  start_date=as.Date(start_date), \n         end_date=as.Date(end_date)) %&gt;%\n  select(type, source, target, start_date, end_date) %&gt;%\n  group_by(source, target, type) %&gt;% \n  summarise(weights = n()) %&gt;% \n  filter(source != target) %&gt;%\n  ungroup()\n\n\nBelow is the distribution of Type column in edges. It indicates that family relationship is negligible.\n\n\nShow code\nmc3_edges$type %&gt;% unique()\n\n\n[1] \"Event.Owns.Shareholdership\"      \"Event.WorksFor\"                 \n[3] \"Event.Owns.BeneficialOwnership\"  \"Relationship.FamilyRelationship\""
  },
  {
    "objectID": "assignment_3.html#graph",
    "href": "assignment_3.html#graph",
    "title": "Take Home Assignment 3",
    "section": "Graph",
    "text": "Graph\nStart with the entity with highest number. Sharon Moon\n\n\nShow code\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes,\n                       edges = mc3_edges,\n                       directed = FALSE) %&gt;% \n  mutate(betweenness_centrality = centrality_betweenness(), \n         closeness_centrality=centrality_closeness())\n\n\n\n\nShow code\ndisplay_graph &lt;- function() {\n  # extract node with highest betweenness centrality\n  top1_betw &lt;- mc3_graph %&gt;% \n    activate(nodes) %&gt;% \n    as_tibble() %&gt;% \n    top_n(1, betweenness_centrality) %&gt;% \n      select(id, type)\n  \n  # extract lvl 1 edges\n  top1_betw_edges_lvl1 &lt;- mc3_edges %&gt;% \n    filter(source %in% top1_betw[[\"id\"]] | target %in% top1_betw[[\"id\"]])\n  \n  # extract nodes from lvl 1 edges\n  id1 &lt;- top1_betw_edges_lvl1 %&gt;%\n    select(source) %&gt;%\n    rename(id = source) %&gt;% \n    left_join(mc3_nodes, by = \"id\") %&gt;% \n    select(id, type)\n  \n  id2 &lt;- top1_betw_edges_lvl1 %&gt;%\n    select(target) %&gt;%\n    rename(id = target) %&gt;% \n    left_join(mc3_nodes, by = \"id\") %&gt;% \n    select(id, type)\n  \n  additional_nodes_lvl1 &lt;- rbind(id1, id2) %&gt;% \n    distinct %&gt;% \n    filter(!id %in% top1_betw[[\"id\"]])\n  \n  # extract lvl 2 edges\n  top1_betw_edges_lvl2 &lt;- mc3_edges %&gt;% \n    filter(source %in% additional_nodes_lvl1[[\"id\"]] | target %in% additional_nodes_lvl1[[\"id\"]])\n  \n  # extract nodes from lvl 1 edges\n  id1 &lt;- top1_betw_edges_lvl2 %&gt;%\n    select(source) %&gt;%\n    rename(id = source) %&gt;% \n    left_join(mc3_nodes, by = \"id\") %&gt;% \n    select(id, type)\n  \n  id2 &lt;- top1_betw_edges_lvl2 %&gt;%\n    select(target) %&gt;%\n    rename(id = target) %&gt;% \n    left_join(mc3_nodes, by = \"id\") %&gt;% \n    select(id, type)\n  \n  additional_nodes_lvl2 &lt;- rbind(id1, id2) %&gt;% \n    distinct %&gt;% \n    filter(!id %in% top1_betw[[\"id\"]] & !id %in% additional_nodes_lvl1[[\"id\"]])\n  \n  # combine all nodes\n  top1_betw_nodes &lt;- rbind(top1_betw, additional_nodes_lvl1, additional_nodes_lvl2) %&gt;%\n    distinct()\n  \n  # combine all edges\n  top1_betw_edges &lt;- rbind(top1_betw_edges_lvl1, top1_betw_edges_lvl2) %&gt;% \n    distinct()\n  \n  # colur palatte for betweenness centrality colours\n  sw_colors &lt;- colorRampPalette(brewer.pal(3, \"RdBu\"))(3)\n  \n  # customise edges for plotting\n  top1_betw_edges &lt;- top1_betw_edges %&gt;% \n    rename(from = source,\n           to = target) %&gt;% \n    mutate(title = paste0(\"Type: \", type), # tooltip when hover over\n           color = \"#0085AF\") # color of edge\n  \n  # customise nodes for plotting\n  top1_betw_nodes &lt;- top1_betw_nodes %&gt;% \n    rename(group = type) %&gt;% \n    mutate(id.type = ifelse(id == top1_betw[[\"id\"]], sw_colors[1], sw_colors[2])) %&gt;%\n    mutate(title = paste0(id, \"&lt;br&gt;Group: \", group), # tooltip when hover over\n           size = 30, # set size of nodes\n           color.border = \"#013848\", # border colour of nodes\n           color.background = id.type, # background colour of nodes\n           color.highlight.background = \"#FF8000\" # background colour of nodes when highlighted\n           )\n\n  # plot graph\n  visNetwork(top1_betw_nodes, top1_betw_edges,\n             height = \"700px\", width = \"100%\",\n             main = paste0(\"Network Graph of \", top1_betw[[\"id\"]])) %&gt;%\n    visIgraphLayout() %&gt;%\n    visGroups(groupname = \"Entity.Organization.Company\", shape = \"triangle\") %&gt;%\n    visGroups(groupname = \"Entity.Organization.FishingCompany\", shape = \"triangle\") %&gt;%\n    visGroups(groupname = \"Entity.Person\", shape = \"circle\") %&gt;%  \n    visGroups(groupname = \"Entity.Person.CEO\", shape = \"circle\") %&gt;%  \n    visOptions(selectedBy = \"group\",\n               highlightNearest = list(enabled = T, degree = 1, hover = T),\n               nodesIdSelection = FALSE) %&gt;% \n    visLayout(randomSeed = 123)\n\n}\n\ndisplay_graph()"
  },
  {
    "objectID": "assignment_3.html#visualization-with-time",
    "href": "assignment_3.html#visualization-with-time",
    "title": "Take Home Assignment 3",
    "section": "Visualization With Time",
    "text": "Visualization With Time\n\n\nShow code\nmc3_edges &lt;- as_tibble(mc3_data$links) %&gt;%\n  mutate(source = as.character(source), target=as.character(target), \n         type = as.character(type),  start_date=as.Date(start_date), \n         end_date=as.Date(end_date)) %&gt;%\n  select(type, source, target, start_date, end_date)\n\nmc3_edges$year &lt;- as.integer(format(mc3_edges$start_date, \"%Y\"))\n\n\nThe year range for start time of activity: 1952 to 2035\n\nmin(mc3_edges$year, na.rm=TRUE)\n\n[1] 1952\n\nmax(mc3_edges$year, na.rm=TRUE)\n\n[1] 2035\n\n\n\n\nShow code\ndisplay_graph_with_time &lt;- function(entity_id, end_year) {\n  mc3_edges &lt;- as_tibble(mc3_data$links) %&gt;%\n    mutate(source = as.character(source), target=as.character(target), \n           type = as.character(type),  start_date=as.Date(start_date), \n           end_date=as.Date(end_date)) %&gt;%\n    select(type, source, target, start_date, end_date)\n    \n  mc3_edges$year &lt;- as.integer(format(mc3_edges$start_date, \"%Y\"))\n  mc3_edges &lt;- mc3_edges %&gt;% \n    filter(year&lt;=end_year) %&gt;%\n    group_by(source, target, type) %&gt;% \n    summarise(weights = n()) %&gt;% \n    filter(source != target) %&gt;%\n    ungroup()\n  \n  mc3_nodes &lt;- mc3_nodes %&gt;%\n  filter(id %in% c(mc3_edges$source, mc3_edges$target))\n  \n  mc3_graph &lt;- tbl_graph(nodes = mc3_nodes, edges = mc3_edges, directed = FALSE) %&gt;% \n    mutate(betweenness_centrality = centrality_betweenness(), closeness_centrality=centrality_closeness())\n  \n  \n  # extract node with highest betweenness centrality\n  top1_betw &lt;- mc3_nodes %&gt;% \n    filter(id==entity_id)\n  \n  # extract lvl 1 edges\n  top1_betw_edges_lvl1 &lt;- mc3_edges %&gt;% \n    filter(source %in% top1_betw[[\"id\"]] | target %in% top1_betw[[\"id\"]])\n  \n  # extract nodes from lvl 1 edges\n  id1 &lt;- top1_betw_edges_lvl1 %&gt;%\n    select(source) %&gt;%\n    rename(id = source) %&gt;% \n    left_join(mc3_nodes, by = \"id\") %&gt;% \n    select(id, type)\n  \n  id2 &lt;- top1_betw_edges_lvl1 %&gt;%\n    select(target) %&gt;%\n    rename(id = target) %&gt;% \n    left_join(mc3_nodes, by = \"id\") %&gt;% \n    select(id, type)\n  \n  additional_nodes_lvl1 &lt;- rbind(id1, id2) %&gt;% \n    distinct %&gt;% \n    filter(!id %in% top1_betw[[\"id\"]])\n  \n  # extract lvl 2 edges\n  top1_betw_edges_lvl2 &lt;- mc3_edges %&gt;% \n    filter(source %in% additional_nodes_lvl1[[\"id\"]] | target %in% additional_nodes_lvl1[[\"id\"]])\n  \n  # extract nodes from lvl 1 edges\n  id1 &lt;- top1_betw_edges_lvl2 %&gt;%\n    select(source) %&gt;%\n    rename(id = source) %&gt;% \n    left_join(mc3_nodes, by = \"id\") %&gt;% \n    select(id, type)\n  \n  id2 &lt;- top1_betw_edges_lvl2 %&gt;%\n    select(target) %&gt;%\n    rename(id = target) %&gt;% \n    left_join(mc3_nodes, by = \"id\") %&gt;% \n    select(id, type)\n  \n  additional_nodes_lvl2 &lt;- rbind(id1, id2) %&gt;% \n    distinct %&gt;% \n    filter(!id %in% top1_betw[[\"id\"]] & !id %in% additional_nodes_lvl1[[\"id\"]])\n  \n  # combine all nodes\n  top1_betw_nodes &lt;- rbind(top1_betw, additional_nodes_lvl1, additional_nodes_lvl2) %&gt;%\n    distinct()\n  \n  # combine all edges\n  top1_betw_edges &lt;- rbind(top1_betw_edges_lvl1, top1_betw_edges_lvl2) %&gt;% \n    distinct()\n  \n  # colur palatte for betweenness centrality colours\n  sw_colors &lt;- colorRampPalette(brewer.pal(3, \"RdBu\"))(3)\n  \n  # customise edges for plotting\n  top1_betw_edges &lt;- top1_betw_edges %&gt;% \n    rename(from = source,\n           to = target) %&gt;% \n    mutate(title = paste0(\"Type: \", type), # tooltip when hover over\n           color = \"#0085AF\") # color of edge\n  \n  # customise nodes for plotting\n  top1_betw_nodes &lt;- top1_betw_nodes %&gt;% \n    rename(group = type) %&gt;% \n    mutate(id.type = ifelse(id == top1_betw[[\"id\"]], sw_colors[1], sw_colors[2])) %&gt;%\n    mutate(title = paste0(id, \"&lt;br&gt;Group: \", group), # tooltip when hover over\n           size = 30, # set size of nodes\n           color.border = \"#013848\", # border colour of nodes\n           color.background = id.type, # background colour of nodes\n           color.highlight.background = \"#FF8000\" # background colour of nodes when highlighted\n           )\n  \n  visNetwork(top1_betw_nodes, top1_betw_edges,\n           height = \"700px\", width = \"100%\",\n           main = paste0(\"Network Graph of \", entity_id)) %&gt;%\n    visIgraphLayout() %&gt;%\n    visGroups(groupname = \"Entity.Organization.Company\", shape = \"triangle\") %&gt;%\n    visGroups(groupname = \"Entity.Organization.FishingCompany\", shape = \"triangle\") %&gt;%\n    visGroups(groupname = \"Entity.Person\", shape = \"circle\") %&gt;%  \n    visGroups(groupname = \"Entity.Person.CEO\", shape = \"circle\") %&gt;%  \n    visOptions(selectedBy = \"group\", highlightNearest = list(enabled = T, degree = 1, hover = T), nodesIdSelection = FALSE) %&gt;% \n    visLayout(randomSeed = 123)\n}\n\n\n\n2020202520302035\n\n\n\ndisplay_graph_with_time('Sharon Moon', 2020)\n\n`summarise()` has grouped output by 'source', 'target'. You can override using\nthe `.groups` argument.\n\n\n\n\n\n\n\n\n\ndisplay_graph_with_time('Sharon Moon', 2025)\n\n`summarise()` has grouped output by 'source', 'target'. You can override using\nthe `.groups` argument.\n\n\n\n\n\n\n\n\n\ndisplay_graph_with_time('Sharon Moon', 2030)\n\n`summarise()` has grouped output by 'source', 'target'. You can override using\nthe `.groups` argument.\n\n\n\n\n\n\n\n\n\ndisplay_graph_with_time('Sharon Moon', 2035)\n\n`summarise()` has grouped output by 'source', 'target'. You can override using\nthe `.groups` argument.\n\n\n\n\n\n\n\n\n\nThe display_graph_with_time(entity_id, year) provides a comprehensive way to visualize corporate structure over time. Due to the limitation of quarto, the visualization is not interactive enough, and could be improved further after migrating to shiny app with a time slider.\nIn general, the corporate structure for Sharon Moon expands quite significantly from 2020 to 2030. Besides, the related entities (level 1 and level 2 entities) also expands. However, the growing speed slows down after 2030, probably due to slower growth rate when reaching certain capacity, or the growth of the whole business slows down from 2030 to 2035."
  },
  {
    "objectID": "in-class/In-class_Ex09.html",
    "href": "in-class/In-class_Ex09.html",
    "title": "ISSS609-AY2023-24T4",
    "section": "",
    "text": "pacman::p_load(scatterPlotMatrix, parallelPlot, cluster, factoextra, tidyverse)\n\n\nwine &lt;- read_csv(\"../data/wine_quality.csv\")\n\nRows: 6497 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): type\ndbl (12): fixed acidity, volatile acidity, citric acid, residual sugar, chlo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nggplot(data = wine, aes(x=type)) + geom_bar()\n\n\n\n\n\nwhitewine &lt;- wine %&gt;%\n  filter(type == \"white\") %&gt;%\n  select(c(1:11))\n\n\nscatterPlotMatrix(whitewine,\n                  corrPlotType = \"Text\",\n                  distribType = 1,\n                  rotateTitle = TRUE,\n                  width=500,\n                  height=500)\n\n\n\n\n\n\nset.seed(123)\nkmeans4 &lt;- kmeans(whitewine, 4, nstart=25)\nprint(kmeans4)\n\nK-means clustering with 4 clusters of sizes 757, 978, 1444, 1719\n\nCluster means:\n  fixed acidity volatile acidity citric acid residual sugar  chlorides\n1      6.981506        0.2965786   0.3563540       9.705878 0.05227081\n2      6.805112        0.2759356   0.3168814       3.607822 0.04012781\n3      6.908172        0.2776939   0.3455402       7.780852 0.04919668\n4      6.782403        0.2719372   0.3247469       5.348342 0.04324549\n  free sulfur dioxide total sulfur dioxide   density       pH sulphates\n1            52.83421             206.8164 0.9965522 3.176975 0.5179392\n2            20.52761              83.1411 0.9919192 3.175256 0.4707566\n3            42.31129             160.3061 0.9951215 3.193996 0.4940651\n4            30.11635             121.1963 0.9931958 3.195829 0.4847935\n    alcohol\n1  9.611471\n2 11.233930\n3 10.120392\n4 10.833256\n\nClustering vector:\n   [1] 3 4 2 1 1 2 4 3 4 4 2 4 2 3 3 4 2 2 3 4 2 2 4 3 4 1 3 4 4 4 4 2 2 4 3 4 3\n  [38] 4 3 3 3 3 3 3 3 3 1 1 3 3 3 4 2 4 4 1 1 3 2 4 4 3 3 2 4 4 4 3 2 4 1 1 1 2\n  [75] 2 4 2 2 4 4 4 3 3 1 3 3 3 1 3 3 3 1 4 4 3 1 3 2 2 3 1 3 3 3 1 4 3 3 3 1 3\n [112] 1 1 3 3 2 4 2 1 1 2 4 4 4 3 3 4 1 3 3 2 1 1 1 1 3 4 3 2 2 2 3 4 2 2 4 3 2\n [149] 2 4 3 3 4 2 2 1 1 4 4 4 4 3 2 1 1 3 1 2 3 4 4 2 2 4 3 3 2 3 4 3 3 1 3 1 1\n [186] 1 3 4 4 1 1 3 4 4 1 1 1 1 1 1 1 1 1 4 4 3 4 4 2 3 2 4 4 4 4 3 3 3 3 3 3 3\n [223] 4 3 4 3 1 1 1 3 4 1 1 1 1 1 1 1 4 3 1 2 2 1 3 1 4 2 2 4 1 1 3 4 3 3 2 2 4\n [260] 2 4 3 2 1 3 3 3 3 3 3 3 3 3 4 1 3 3 2 2 4 4 4 1 1 1 3 1 1 1 1 1 3 1 3 3 3\n [297] 3 1 3 4 2 2 2 3 3 3 3 3 4 3 2 3 3 3 3 4 4 4 4 2 2 4 4 4 1 1 1 3 1 2 4 4 2\n [334] 4 2 2 4 3 4 3 3 4 4 3 3 4 2 3 4 3 3 4 4 4 1 1 1 3 3 3 3 2 4 1 2 4 3 3 3 2\n [371] 3 3 1 3 2 2 4 2 3 4 2 3 3 3 4 2 4 1 4 1 1 2 4 2 3 3 2 4 3 2 4 3 4 1 3 3 4\n [408] 4 4 2 3 3 2 2 3 3 2 1 2 4 4 1 1 1 3 1 1 1 2 1 1 2 1 3 4 2 1 1 1 4 2 4 4 1\n [445] 3 2 3 4 4 4 3 4 3 4 4 4 2 4 1 1 4 3 3 2 3 4 3 2 3 1 3 1 2 4 4 1 4 4 3 3 3\n [482] 4 4 3 1 4 4 2 3 3 2 2 3 3 4 3 1 3 3 1 1 3 1 1 3 3 4 3 3 3 3 3 4 2 4 3 3 3\n [519] 2 2 4 4 2 2 2 4 2 4 4 4 4 3 3 3 3 3 3 3 2 1 3 1 3 3 3 3 3 2 4 1 3 2 4 3 4\n [556] 2 3 4 3 3 3 4 3 4 3 2 2 3 3 3 1 4 3 3 4 1 1 3 4 4 1 4 3 2 4 2 3 4 4 4 4 4\n [593] 3 4 4 4 3 4 4 2 3 4 4 4 4 4 3 3 3 2 4 2 4 4 4 4 2 1 1 4 1 3 4 2 4 4 3 1 1\n [630] 2 3 3 4 1 3 4 4 3 1 1 4 1 1 3 3 3 3 3 1 1 1 1 1 4 3 4 2 4 1 1 2 4 3 2 3 4\n [667] 1 3 3 1 1 2 3 4 1 1 1 2 2 2 3 3 3 3 3 1 4 1 1 4 4 1 1 3 1 1 2 1 1 1 1 4 2\n [704] 4 4 2 1 3 4 2 3 4 4 1 1 3 1 3 3 4 3 3 4 2 4 4 4 2 3 3 4 1 2 3 1 4 3 1 3 4\n [741] 2 2 4 3 3 4 1 3 3 3 3 3 3 1 4 4 3 3 3 4 3 3 1 4 3 4 1 2 4 4 4 3 3 3 4 4 2\n [778] 1 3 3 2 1 3 3 1 4 4 4 4 4 4 2 3 2 3 3 1 3 4 2 3 1 1 3 4 3 1 1 1 1 1 4 3 3\n [815] 1 4 2 4 4 4 2 1 4 4 2 3 3 4 2 2 4 3 4 2 4 4 3 3 3 4 4 3 3 4 4 4 3 2 3 4 4\n [852] 3 4 3 4 4 3 3 3 3 4 1 3 4 3 4 4 3 3 2 3 3 4 2 2 4 4 4 4 4 4 4 4 4 1 4 3 2\n [889] 3 2 3 4 4 4 4 2 1 2 2 1 3 4 1 1 3 2 2 4 3 1 4 4 4 2 2 2 4 4 4 4 3 3 3 1 3\n [926] 2 2 3 3 4 2 1 1 1 1 1 2 4 1 1 1 1 2 4 4 4 1 3 2 2 4 4 2 4 4 4 4 2 2 3 3 4\n [963] 3 4 3 2 1 3 2 2 2 4 3 2 4 4 4 1 3 2 2 3 2 2 3 4 3 3 3 4 3 2 1 2 3 3 2 3 3\n[1000] 3 2 1 1 4 3 2 3 2 1 3 4 3 2 1 3 4 4 4 3 1 4 4 1 3 3 4 3 2 4 1 3 1 1 1 1 3\n[1037] 2 2 4 2 4 2 4 1 2 2 4 2 2 4 3 4 2 4 2 4 4 1 4 3 4 1 1 1 3 4 3 4 2 3 3 4 4\n[1074] 1 3 4 3 4 1 1 4 3 3 1 4 3 4 4 1 4 1 3 3 4 1 2 3 4 4 4 3 4 3 4 3 1 4 2 2 3\n[1111] 2 2 3 2 2 2 2 1 2 4 4 4 2 4 4 3 3 2 2 4 3 4 3 4 4 3 3 3 4 2 2 3 4 4 4 1 3\n[1148] 3 4 1 1 1 2 2 3 3 4 4 1 4 3 4 3 1 2 4 2 4 2 3 4 4 4 4 1 3 1 3 3 4 4 4 4 4\n[1185] 4 1 3 4 3 2 4 4 4 4 1 3 4 4 4 2 2 2 1 2 2 1 3 1 4 4 2 3 3 2 2 3 2 1 4 2 1\n[1222] 4 4 3 4 2 4 4 4 2 1 4 2 4 3 1 2 4 4 3 3 3 3 4 4 1 3 2 2 1 3 3 3 3 3 4 3 1\n[1259] 1 1 1 3 3 1 2 3 4 3 4 1 3 4 3 4 1 4 3 4 4 3 4 3 3 3 3 4 3 4 4 2 2 1 2 2 2\n[1296] 1 4 4 3 3 3 3 1 3 1 4 4 4 4 2 3 4 3 3 3 3 1 3 2 1 4 4 3 3 3 4 3 3 2 4 4 4\n[1333] 1 3 4 1 3 1 1 4 4 3 4 3 3 4 3 3 3 2 4 4 1 1 3 3 1 3 4 4 3 1 4 2 3 4 2 4 1\n[1370] 1 4 3 3 3 4 4 4 4 4 4 3 2 2 2 4 4 4 2 4 1 4 2 2 2 4 2 4 1 1 2 1 1 4 4 2 4\n[1407] 2 2 1 4 2 2 3 4 4 2 4 1 4 4 4 2 4 1 4 4 4 3 2 2 4 2 2 2 3 2 1 2 1 1 3 4 4\n[1444] 4 3 4 2 3 3 3 3 4 3 3 1 3 2 4 3 4 4 3 3 4 3 3 3 2 2 4 3 3 2 4 2 3 3 2 3 4\n[1481] 3 4 1 2 4 4 2 3 1 1 4 2 1 3 1 1 2 4 2 3 4 3 4 4 4 4 1 3 3 4 4 4 4 3 4 4 3\n[1518] 3 2 3 3 4 3 3 3 3 3 1 3 3 3 3 1 4 3 4 2 3 4 4 3 2 4 2 2 3 3 3 4 4 3 4 3 3\n[1555] 3 3 3 3 4 2 3 4 4 3 4 4 3 4 1 3 3 1 3 4 4 1 2 4 3 1 4 2 4 3 1 3 3 1 3 4 3\n[1592] 3 4 2 4 1 4 1 4 2 4 1 2 2 4 4 4 4 1 1 4 2 2 4 4 3 1 4 1 4 2 4 3 4 4 3 1 4\n[1629] 4 2 4 4 4 4 1 4 3 3 1 4 3 3 4 3 4 3 3 2 2 3 4 1 4 3 3 4 2 3 1 1 1 1 4 3 3\n[1666] 4 2 4 2 4 3 2 3 3 1 1 2 3 3 4 1 1 1 1 1 1 3 1 1 4 3 1 1 1 3 4 1 1 1 3 4 1\n[1703] 4 3 3 4 3 3 3 3 2 4 3 4 4 3 4 4 3 2 3 1 3 3 4 3 2 1 4 4 4 1 4 4 1 3 2 1 2\n[1740] 2 3 3 3 3 4 1 2 3 2 4 3 3 1 3 2 3 1 1 2 1 1 4 2 4 1 1 1 3 3 4 3 3 3 3 2 4\n[1777] 3 3 3 3 3 1 3 2 4 3 4 3 4 1 3 4 3 1 4 3 4 4 3 3 1 2 3 3 1 4 4 1 4 1 3 4 2\n[1814] 4 2 3 4 4 2 4 3 4 2 1 3 2 3 1 1 3 3 3 3 3 3 1 4 4 1 4 3 4 1 4 2 3 3 3 1 1\n[1851] 3 2 4 4 3 1 3 3 3 1 3 1 4 1 4 4 1 4 3 3 3 3 3 3 3 3 3 2 1 2 1 2 1 1 4 2 4\n[1888] 3 1 4 1 1 3 3 3 1 3 3 2 4 3 4 3 4 1 3 4 3 2 4 3 2 4 3 4 2 3 2 3 1 3 4 4 2\n[1925] 2 2 2 3 1 3 1 1 2 3 2 3 1 3 2 3 1 3 1 1 1 3 3 1 4 3 1 3 4 3 1 3 2 2 1 2 2\n[1962] 4 2 1 3 3 4 1 3 3 4 3 4 4 4 1 1 3 4 1 1 1 1 1 1 3 3 3 1 4 4 1 2 3 3 3 3 3\n[1999] 3 1 3 3 3 3 3 3 3 2 3 2 2 3 3 4 2 2 4 2 4 4 3 3 1 3 1 3 2 3 3 1 4 3 2 1 4\n[2036] 2 3 3 4 2 1 4 4 4 4 2 4 3 3 3 4 3 3 2 2 3 3 3 1 3 1 2 4 4 3 4 4 3 4 4 3 4\n[2073] 3 1 3 4 4 1 4 4 4 2 4 4 3 3 2 3 4 3 3 3 2 4 4 3 4 3 3 3 3 2 1 4 3 4 1 3 3\n[2110] 1 3 3 3 2 1 3 2 4 4 4 3 4 3 3 4 3 3 1 3 4 4 3 3 3 4 1 4 1 2 2 4 4 3 2 3 3\n[2147] 4 4 2 2 4 4 2 2 1 3 2 2 4 2 4 2 4 2 4 3 3 1 1 1 1 1 4 3 1 1 4 4 3 4 3 4 3\n[2184] 3 4 2 2 4 2 4 4 3 3 4 2 4 2 2 1 1 3 3 1 3 3 3 4 4 4 4 3 4 4 4 4 3 2 4 3 4\n[2221] 4 3 3 3 3 3 3 3 4 3 4 3 2 3 2 4 1 3 3 4 3 1 3 3 1 4 3 3 2 1 1 4 3 1 3 4 4\n[2258] 4 1 4 1 4 2 3 3 3 3 3 3 3 4 3 4 2 4 3 1 2 1 3 2 2 1 1 1 1 3 3 1 2 4 3 1 2\n[2295] 4 3 3 1 4 4 4 4 1 4 3 3 4 3 4 4 3 4 4 2 4 3 4 3 3 2 4 3 4 3 1 4 4 4 4 3 1\n[2332] 3 1 4 1 4 1 3 3 2 3 3 2 3 2 1 3 2 4 3 1 1 4 2 2 4 4 2 1 4 4 2 3 3 1 4 1 1\n[2369] 3 3 4 1 2 2 1 3 1 2 1 1 1 3 4 2 4 3 3 3 2 2 4 3 4 4 1 1 1 2 2 2 2 4 1 4 4\n[2406] 1 2 4 1 4 1 1 1 4 1 4 1 1 2 1 4 1 1 4 1 4 3 1 3 1 1 3 1 1 1 4 3 3 3 4 3 3\n[2443] 1 1 1 1 1 4 4 1 3 3 4 4 1 1 3 3 1 3 3 2 2 3 4 3 3 4 2 4 3 3 2 4 2 4 3 2 1\n[2480] 4 4 1 1 1 1 1 4 4 4 3 4 1 3 4 4 3 2 4 4 3 4 1 4 4 3 1 1 4 3 4 1 1 2 4 3 2\n[2517] 3 1 2 1 3 4 3 3 3 3 4 4 4 3 3 3 3 3 2 3 4 4 4 4 3 3 3 4 4 3 3 4 1 1 4 1 4\n[2554] 3 3 3 3 3 3 4 2 4 2 4 3 1 2 4 1 4 4 2 2 3 3 1 1 1 4 4 3 3 3 3 3 3 3 2 3 3\n[2591] 4 3 3 3 4 3 1 4 1 1 4 1 4 4 4 2 3 1 1 2 3 1 4 4 2 4 4 4 4 3 3 4 4 4 2 3 4\n[2628] 4 1 1 4 4 1 3 1 2 3 1 4 2 2 3 2 3 3 4 2 4 3 3 3 3 2 3 1 1 1 4 3 2 3 3 4 2\n[2665] 2 4 3 4 4 3 3 3 4 2 4 4 2 3 4 4 4 3 4 4 4 2 4 1 3 4 4 4 3 4 4 4 3 2 3 4 2\n[2702] 4 4 4 1 1 1 4 1 1 1 3 3 1 1 3 1 3 2 3 2 3 4 4 3 3 2 4 1 2 1 3 4 2 3 1 4 2\n[2739] 4 2 3 4 3 2 2 2 3 4 3 4 3 4 4 2 2 1 1 2 2 4 3 3 3 4 3 4 2 3 4 3 1 4 4 2 4\n[2776] 4 4 4 2 4 4 3 1 1 1 3 2 3 3 3 1 1 1 4 3 2 4 3 4 4 1 1 2 2 2 4 3 3 1 3 2 4\n[2813] 4 3 2 2 4 2 3 4 4 1 3 2 3 3 1 3 3 3 3 3 2 4 4 3 1 3 2 2 2 2 2 2 2 2 2 2 3\n[2850] 1 3 2 3 4 2 3 4 2 3 4 3 2 2 2 4 4 4 4 4 4 4 2 3 2 4 2 3 3 4 2 2 2 4 2 4 2\n[2887] 2 2 2 4 3 3 1 3 2 3 1 1 2 3 2 2 3 2 4 3 1 2 2 2 3 3 2 1 2 2 4 4 2 4 2 1 4\n[2924] 4 4 1 2 3 3 4 3 2 1 4 2 2 2 1 4 4 4 4 3 4 4 3 4 4 1 4 4 2 4 4 2 4 2 2 2 2\n[2961] 4 4 2 4 4 4 4 4 3 2 3 4 4 4 4 3 4 4 4 4 4 2 1 3 2 4 4 4 2 1 3 3 4 4 4 4 4\n[2998] 3 4 4 4 4 3 2 4 3 1 3 3 1 1 4 2 4 2 2 4 3 4 2 2 2 4 2 4 3 4 3 4 4 4 4 2 1\n[3035] 3 2 1 3 4 1 4 3 3 4 4 2 4 3 4 1 1 1 3 4 2 4 2 4 1 2 3 3 4 3 1 4 1 4 4 2 4\n[3072] 2 3 4 4 2 4 1 2 4 2 3 2 2 2 2 2 1 2 2 2 1 3 4 2 2 2 4 4 4 4 2 4 4 4 3 3 3\n[3109] 3 1 4 2 4 4 4 4 2 2 3 2 1 4 4 2 4 3 4 2 2 4 3 1 4 4 4 1 4 4 4 4 1 2 4 4 4\n[3146] 4 4 3 4 3 2 4 1 2 4 4 4 4 4 4 2 4 4 4 1 4 4 4 2 4 3 2 4 4 4 3 2 3 2 4 2 4\n[3183] 4 2 2 4 2 4 4 3 4 3 4 4 2 4 4 4 4 4 3 4 2 4 3 3 2 4 3 3 4 3 4 3 2 2 4 4 4\n[3220] 2 2 2 4 3 3 2 4 1 1 4 3 4 2 2 4 3 3 3 4 2 4 4 4 2 2 4 4 3 3 3 4 3 4 4 1 1\n[3257] 1 1 1 1 1 2 1 2 1 3 4 3 4 1 4 2 2 4 4 2 3 4 1 4 4 4 4 3 4 4 4 4 3 1 2 2 1\n[3294] 2 4 1 1 1 4 4 2 2 2 2 3 2 3 1 4 2 4 3 2 2 1 2 2 4 4 3 4 2 4 2 4 4 3 2 4 4\n[3331] 3 3 3 3 2 1 1 1 2 2 4 2 4 1 1 1 1 3 2 2 4 2 2 2 4 4 3 2 2 2 2 2 4 2 2 2 4\n[3368] 4 3 4 4 4 3 4 3 4 3 1 3 1 4 4 4 3 3 4 3 1 2 2 4 4 2 4 1 1 4 1 1 2 4 4 4 4\n[3405] 2 4 2 1 1 4 3 4 3 1 3 3 1 2 1 3 3 2 4 3 4 3 3 3 4 3 3 3 4 2 2 2 2 4 1 4 4\n[3442] 4 2 4 1 4 3 2 4 4 4 4 4 2 4 2 3 3 4 3 4 1 4 4 3 4 4 1 2 3 1 4 4 2 1 3 2 3\n[3479] 3 2 2 4 2 2 2 4 2 1 2 2 3 4 4 4 4 4 3 3 4 4 4 4 3 2 4 4 3 4 3 3 3 2 4 2 2\n[3516] 2 3 4 4 4 1 3 3 1 4 4 4 3 2 4 3 3 2 3 3 3 2 4 4 2 2 4 3 3 3 1 3 1 4 3 4 4\n[3553] 4 4 2 4 4 2 4 2 2 2 3 2 2 2 4 2 2 2 2 2 4 2 4 4 3 4 4 2 3 4 2 2 2 4 3 4 4\n[3590] 4 4 3 3 3 4 4 4 3 3 1 2 4 4 4 2 3 3 2 3 3 3 2 4 3 3 2 1 4 4 4 3 4 2 4 2 1\n[3627] 4 1 3 3 4 4 4 4 3 2 2 4 2 2 4 3 3 4 4 3 2 2 4 4 4 1 4 1 4 4 1 4 3 4 4 3 2\n[3664] 3 3 4 3 4 2 4 3 2 2 2 4 3 2 3 4 4 1 4 4 1 4 1 3 2 1 4 3 4 4 4 4 3 4 1 2 3\n[3701] 3 4 3 3 3 3 2 4 1 3 2 3 3 1 2 1 3 4 4 1 3 4 4 3 4 4 4 3 2 4 1 3 4 4 4 2 2\n[3738] 4 4 3 3 3 3 3 3 3 4 1 4 3 3 4 3 3 4 4 4 3 3 4 4 2 2 2 4 1 1 1 4 1 4 4 4 4\n[3775] 1 4 4 4 4 2 1 4 2 1 4 2 1 1 1 1 1 1 4 3 4 4 2 2 4 3 2 2 4 4 2 2 2 4 4 4 3\n[3812] 3 4 3 3 4 4 4 4 4 4 3 1 1 4 2 4 2 4 2 4 4 4 4 3 4 4 4 3 4 2 1 4 4 2 3 4 3\n[3849] 2 2 4 4 2 4 4 3 2 4 4 1 1 3 1 1 2 4 4 1 1 3 3 1 1 3 1 4 3 2 3 2 4 4 4 3 4\n[3886] 2 3 2 4 4 2 4 4 2 4 2 3 3 4 4 2 2 2 2 4 2 2 2 4 4 3 4 2 4 4 4 3 1 4 4 4 3\n[3923] 2 4 4 2 2 4 3 3 2 4 4 2 2 1 4 3 2 3 3 3 4 4 3 3 4 3 4 3 3 3 2 4 3 2 4 2 4\n[3960] 4 3 3 4 4 3 2 4 1 1 4 3 4 2 1 1 3 4 4 1 1 3 3 3 4 4 4 4 1 4 4 1 4 2 4 4 4\n[3997] 4 3 4 4 4 4 2 4 4 4 2 4 2 3 4 3 4 3 1 2 3 4 1 2 2 4 3 3 3 2 3 3 2 4 4 4 4\n[4034] 4 4 3 3 3 4 4 1 3 4 4 4 4 3 4 4 2 4 2 3 4 3 2 4 4 4 2 2 2 4 4 2 4 3 3 3 4\n[4071] 3 2 3 4 2 4 4 4 4 2 4 4 3 3 2 2 2 4 2 4 3 2 4 2 2 2 4 2 4 4 2 3 3 2 2 4 3\n[4108] 3 4 3 1 2 2 2 4 2 3 3 4 3 4 3 3 2 2 3 3 1 1 2 4 1 1 4 2 4 4 1 2 3 3 3 4 4\n[4145] 3 3 4 3 4 2 1 1 4 1 1 1 1 3 3 3 3 3 3 4 4 2 3 4 4 4 3 4 3 2 3 3 3 4 4 1 4\n[4182] 2 3 2 2 1 2 4 4 4 2 4 2 2 2 2 2 3 3 2 2 2 4 3 4 2 3 4 2 2 4 1 3 2 1 1 1 4\n[4219] 3 1 2 4 4 2 2 1 3 2 1 4 4 2 2 4 4 4 4 2 4 2 4 3 3 2 4 4 2 4 4 3 2 2 2 2 4\n[4256] 4 4 4 4 4 3 4 3 3 4 3 4 4 3 1 3 1 4 4 4 4 4 3 2 4 4 4 4 2 2 2 2 4 2 4 4 1\n[4293] 4 1 4 1 4 4 4 3 3 3 1 4 4 4 4 4 2 4 3 4 4 2 4 4 2 3 4 4 1 3 4 4 4 3 3 3 3\n[4330] 3 3 3 3 3 3 3 3 3 3 2 3 4 3 4 4 4 4 3 3 1 2 4 3 3 3 4 3 1 3 1 3 4 4 4 4 3\n[4367] 4 4 4 4 4 2 4 2 3 1 4 2 4 4 3 3 4 2 3 3 3 2 2 4 3 1 3 3 3 3 3 3 3 3 3 4 3\n[4404] 1 1 1 4 2 1 4 3 2 4 2 4 4 3 4 4 4 4 4 4 4 4 4 4 1 3 3 3 2 2 1 3 3 2 3 4 4\n[4441] 3 4 3 4 4 4 4 2 4 3 4 1 3 2 3 3 3 3 4 4 3 3 4 4 4 4 3 3 2 4 2 2 2 4 4 4 4\n[4478] 3 3 4 4 3 3 4 4 2 2 2 4 4 4 2 2 3 2 1 2 3 4 2 3 3 3 4 4 3 4 2 3 2 3 4 4 2\n[4515] 1 4 2 2 2 3 1 1 2 3 3 3 1 2 2 3 3 3 4 4 4 3 3 2 4 2 4 4 2 2 4 4 2 2 1 2 2\n[4552] 4 4 4 4 2 4 1 4 4 4 2 4 4 4 3 3 3 4 4 2 2 2 2 4 4 2 2 2 4 4 4 3 3 4 3 4 4\n[4589] 4 4 3 1 3 4 4 4 4 2 4 2 4 4 3 4 3 2 4 3 2 2 2 2 3 3 3 4 2 4 4 1 4 2 4 4 2\n[4626] 3 1 2 2 2 4 4 1 1 4 4 3 4 3 1 4 4 2 1 4 3 2 4 1 2 2 4 1 2 3 3 3 3 4 2 2 3\n[4663] 4 4 4 4 1 4 4 4 3 3 3 4 3 3 4 4 3 3 4 2 2 4 1 4 4 3 3 3 3 3 3 3 3 4 2 4 4\n[4700] 3 3 3 3 2 1 4 4 4 4 3 4 4 4 2 4 2 2 4 4 2 2 2 4 3 2 4 2 4 4 2 4 3 3 4 2 2\n[4737] 2 4 4 2 1 4 4 3 2 1 4 2 3 3 3 1 2 4 4 2 4 4 4 4 4 4 2 4 4 2 4 3 3 3 3 3 1\n[4774] 2 4 4 4 4 4 2 4 3 4 4 3 2 4 4 3 4 4 4 4 3 3 3 3 2 4 4 4 3 4 4 2 2 4 4 2 3\n[4811] 3 2 4 3 4 4 3 4 2 4 3 4 3 4 3 4 4 2 3 2 4 4 4 2 2 4 2 1 4 2 4 1 2 3 3 2 3\n[4848] 4 3 3 3 3 4 2 2 3 3 4 3 4 4 2 2 2 3 2 4 2 4 2 4 2 3 4 4 2 4 2 2 3 3 4 3 3\n[4885] 3 3 4 2 4 4 2 4 4 2 3 4 4 2\n\nWithin cluster sum of squares by cluster:\n[1] 681403.3 357903.9 579703.3 462118.7\n (between_SS / total_SS =  80.0 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\n\nfviz_cluster(kmeans4, data=whitewine)\n\n\n\n\n\nwhitewine &lt;- whitewine %&gt;%\n  mutate(Cluster = kmeans4$cluster)\n\n\nwhitewine$Cluster &lt;- \n  as_factor(whitewine$Cluster)\n\n\nwhitewine %&gt;%\n  parallelPlot(refColumnDim = \"Cluster\",\n               width = 300,\n               height = 250,\n               rotateTitle = TRUE)"
  }
]